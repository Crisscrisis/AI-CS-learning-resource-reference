# ML学习路线
## 基础知识
### 线性回归
#### 梯度下降
<https://medium.com/@saishruthi.tn/gradient-descent-algorithms-cefa1945a774>
#### 梯度下降算法实现
<https://www.jianshu.com/p/c7e642877b0e>
#### 线性回归
<https://developer.aliyun.com/article/727179>
#### 梯度下降python实现
<https://medium.com/@zhaoyi0113/python-implementation-of-batch-gradient-descent-379fa19eb428>

### logistic 回归
#### 机器学习中的交叉熵
<https://blog.csdn.net/tsyccnh/article/details/79163834>
#### 相对熵
<https://www.jianshu.com/p/43318a3dc715>
#### 交叉熵和相对熵的通俗解释
<https://www.zhihu.com/question/41252833>
#### 直观讲解信息熵，相对熵，交叉熵
<https://charlesliuyx.github.io/2017/09/11/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BF%A1%E6%81%AF%E7%86%B5%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5%E5%92%8C%E7%9B%B8%E5%AF%B9%E7%86%B5/>

### softmax 回归
#### softmax 回归
<http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/>
#### softmax 详细推导
<https://blog.csdn.net/bqw18744018044/article/details/83120425>
#### softmax 解释
<https://blog.csdn.net/bitcarmanlee/article/details/82320853>

### 神经网络
#### perceptron
<http://www.wikiwand.com/en/Perceptron>

<https://zhuanlan.zhihu.com/p/26307123>

<https://blog.csdn.net/Dream_angel_Z/article/details/48915561>
#### MLP
http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/

### 反向传播
#### 反向传播
<https://zhuanlan.zhihu.com/p/44412855>

<https://mattmazur.com/2015/03/17/a-step-by-step-backpropagation-example/>
#### bp详细推导
<https://blog.csdn.net/qq_32865355/article/details/80260212>
#### 理解最小二乘法（bp中损失函数使用最小二乘法的原因）
<https://blog.csdn.net/ccnt_2012/article/details/81127117>

### 训练问题
#### 梯度消失和梯度爆炸
<https://blog.csdn.net/qq_25737169/article/details/78847691>

<https://zhuanlan.zhihu.com/p/25631496>
#### batch norm
<https://www.zhihu.com/question/38102762>

<https://blog.csdn.net/qq_25737169/article/details/79048516>
#### 各种loss比较
<https://en.wikipedia.org/wiki/Loss_functions_for_classification>

<https://medium.com/@phuctrt/loss-functions-why-what-where-or-when-189815343d3f>
#### 各种activation function比较
<https://medium.com/@phuctrt/activation-functions-when-to-use-them-and-how-could-they-perform-e428f7340e6d>

### 网络结构
#### 理解LSTM
<https://www.jianshu.com/p/9dc9f41f0b29>
#### 理解Resnet
<https://zhuanlan.zhihu.com/p/31852747>

### 正则化
#### 机器学习中的范数规则化之1 L0、L1与L2范数
<https://blog.csdn.net/zouxy09/article/details/24971995>
#### 机器学习中的范数规则化之2 核范数与规则项参数选择
<https://blog.csdn.net/zouxy09/article/details/24972869>
#### 机器学习中正则化项L1和L2的直观理解
<https://blog.csdn.net/jinping_shi/article/details/52433975>
#### 带约束的最优化问题
<https://blog.csdn.net/NewThinker_wei/article/details/52857397>
#### 正则化方法：L1和L2 regularization、数据集扩增、dropout
<https://blog.csdn.net/u012162613/article/details/44261657>
#### 斯坦福机器学习课程 第三周 4正则化：解决过拟合问题
<http://studyai.site/2016/09/04/%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%AF%BE%E7%A8%8B%20%E7%AC%AC%E4%B8%89%E5%91%A8%20(4)%E6%AD%A3%E5%88%99%E5%8C%96%EF%BC%9A%E8%A7%A3%E5%86%B3%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/>

### SVM
#### 支持向量机通俗导论(理解SVM的三层境界)
<https://blog.csdn.net/v_JULY_v/article/details/7624837>
#### 机器学习算法复习手册——SVM
<https://cloud.tencent.com/developer/article/1561093>
#### 机器学习实战教程（八）：支持向量机原理篇之手撕线性SVM
<https://cuijiahua.com/blog/2017/11/ml_8_svm_1.html>
#### 机器学习实战教程（九）：支持向量机实战篇之再撕非线性SVM
<https://cuijiahua.com/blog/2017/11/ml_9_svm_2.html>
#### 真正理解拉格朗日乘子法和KKT条件
<https://blog.csdn.net/weixin_41500849/article/details/80493712>
#### 零基础学SVM—Support Vector Machine(一)
<https://zhuanlan.zhihu.com/p/24638007>

## 机器学习轻量化
### 矩阵乘法数据分块
#### 深度学习加速：算法、编译器、体系结构与硬件设计
<https://zhuanlan.zhihu.com/p/101544149>
#### 通用矩阵乘（GEMM）优化与卷积计算
<https://zhuanlan.zhihu.com/p/66958390>

## 网络架构
### RNN
#### 全面理解RNN及其不同架构
<https://zhuanlan.zhihu.com/p/34152808>
### LSTM & GRU
#### 深入理解lstm及其变种gru
<https://zhuanlan.zhihu.com/p/34203833>
#### 人人都能看懂的GRU
<https://zhuanlan.zhihu.com/p/32481747>
#### 难以置信！LSTM和GRU的解析从未如此清晰
<https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/82922386>
### CNN
#### CNN的直观解释
<https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/>

## 应用
### 姿态识别
#### 2D3D姿态识别
<https://mp.weixin.qq.com/s__biz=MzU5MzQyMzk5OQ==&mid=2247484885&idx=1&sn=09aaafd71959a9c0db703993f8386bd5&chksm=fe11fec5c96677d3580e5f9ee7c9c4c5f4c31257442625afa5ae59e2f2954940e3c3a50acc33&mpshare=1&scene=1&srcid=#rd>
#### 姿态识别综述
<https://medium.com/beyondminds/an-overview-of-human-pose-estimation-with-deep-learning-d49eb656739b>
#### 姿态识别综述翻译
<https://www.infoq.cn/article/6Btg0-1crfmb7svRGa6H>
#### 通俗易懂讲解openPose原理
<https://blog.csdn.net/tangbin2009/article/details/81122788>
#### openPose算法解析
<https://www.jianshu.com/p/98c11545d4fb>
#### openPose详细解析
<https://arvrjourney.com/human-pose-estimation-using-openpose-with-tensorflow-part-1-7dd4ca5c8027>

<https://arvrjourney.com/human-pose-estimation-using-openpose-with-tensorflow-part-2-e78ab9104fc8>
