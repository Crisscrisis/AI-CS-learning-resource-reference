# ML学习路线
## 基础知识
#### 机器学习中的交叉熵
<https://blog.csdn.net/tsyccnh/article/details/79163834>
#### 相对熵
<https://www.jianshu.com/p/43318a3dc715>
#### 交叉熵和相对熵的通俗解释
<https://www.zhihu.com/question/41252833>
#### 直观讲解信息熵，相对熵，交叉熵
<https://charlesliuyx.github.io/2017/09/11/%E4%BB%80%E4%B9%88%E6%98%AF%E4%BF%A1%E6%81%AF%E7%86%B5%E3%80%81%E4%BA%A4%E5%8F%89%E7%86%B5%E5%92%8C%E7%9B%B8%E5%AF%B9%E7%86%B5/>
#### softmax 回归
<http://deeplearning.stanford.edu/tutorial/supervised/SoftmaxRegression/>
#### softmax 详细推导
<https://blog.csdn.net/bqw18744018044/article/details/83120425>
#### softmax 解释
<https://blog.csdn.net/bitcarmanlee/article/details/82320853>
#### perceptron
http://www.wikiwand.com/en/Perceptron
https://zhuanlan.zhihu.com/p/26307123
https://blog.csdn.net/Dream_angel_Z/article/details/48915561
#### MLP，back propagation
http://ufldl.stanford.edu/tutorial/supervised/MultiLayerNeuralNetworks/
